{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from mtcnn import MTCNN\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from PIL import Image\n",
    "import io\n",
    "import threading\n",
    "from flask import Flask, request, jsonify\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'results.csv'\n",
    "data = pd.read_csv(csv_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "vgg_face_64 = tf.keras.models.load_model('vgg_face_model_64.h5')\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def extract_face(pixels, required_size=(224, 224)):\n",
    "\n",
    "    detector = MTCNN()\n",
    "\t\n",
    "    results = detector.detect_faces(pixels)\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "\t\n",
    "    face = pixels[y1:y2, x1:x2]\n",
    "\t\n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize(required_size)\n",
    "    face_array = asarray(image)\n",
    "    face_array = face_array.astype('float32')\n",
    "    \n",
    "    img_array = np.expand_dims(face_array, axis=0)\n",
    "    img_array = preprocess_input(img_array, version=2)\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "\n",
    "def generate_hashcode(img):\n",
    "    img_array = extract_face(img)\n",
    "    vect = vgg_face_64.predict(img_array)\n",
    "    hashcode = np.where(vect >= 0.5, 1, 0)\n",
    "    return hashcode\n",
    "\n",
    "\n",
    "# Function to compare vectors and show information if the difference is less than the threshold\n",
    "def compare_and_get_info(image, threshold=5):\n",
    "    \n",
    "    hashcode_64 = generate_hashcode(image)\n",
    "    \n",
    "    for index, row in (data.iterrows()):\n",
    "        csv_vector = row[1]\n",
    "        vector_str_clean = csv_vector.replace(\"\\n\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").strip()\n",
    "        csv_vector = np.array(list(map(int, vector_str_clean.split())), dtype=int)\n",
    "        \n",
    "        differences = np.sum(hashcode_64 != csv_vector) \n",
    "        \n",
    "        if differences < threshold:\n",
    "            matched_person = {\n",
    "            'Image' : row[0],\n",
    "            'Name': row[2],\n",
    "            'Age': row[3],\n",
    "            'Job': row[4]\n",
    "            }\n",
    "            return matched_person\n",
    "    return None\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/get_infos', methods=['POST'])\n",
    "def get_infos():\n",
    "\tif 'image' not in request.files:\n",
    "\t\treturn jsonify({'error': 'No image provided'}), 400\n",
    "\n",
    "\tfile = request.files['image']\n",
    "\tif file.filename == '':\n",
    "\t\treturn jsonify({'error': 'No selected file'}), 400\n",
    "\n",
    "\timg = Image.open(io.BytesIO(file.read()))\n",
    "\timg = np.array(img)\n",
    "\n",
    "\tmatched_person = compare_and_get_info(img)\n",
    "\tif matched_person:\n",
    "\t\treturn jsonify(matched_person), 200\n",
    "\telse:\n",
    "\t\treturn jsonify({'error': 'No match found'}), 404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_35940\\2751737504.py:39: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  csv_vector = row[1]\n",
      "127.0.0.1 - - [09/Jan/2025 17:23:15] \"POST /get_infos HTTP/1.1\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001714FE63880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "WARNING:tensorflow:6 out of the last 17 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001714FE63880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_35940\\2751737504.py:47: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  'Image' : row[0],\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_35940\\2751737504.py:48: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  'Name': row[2],\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_35940\\2751737504.py:49: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  'Age': row[3],\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_35940\\2751737504.py:50: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  'Job': row[4]\n",
      "127.0.0.1 - - [09/Jan/2025 17:28:31] \"POST /get_infos HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jan/2025 17:29:44] \"POST /get_infos HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jan/2025 17:32:09] \"POST /get_infos HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "def run_app():\n",
    "    app.run(debug=False, use_reloader=False)\n",
    "\n",
    "# Run Flask app in a separate thread\n",
    "thread = threading.Thread(target=run_app)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: 22\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://127.0.0.1:5000/get_infos'\n",
    "image_path = r\"C:\\Users\\LENOVO\\Pictures\\WIN_20230220_17_14_34_Pro.jpg\"\n",
    "with open(image_path, 'rb') as img_file:\n",
    "    files = {'image': img_file}\n",
    "    response = requests.post(url, files=files)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Age:\", response.json().get('Age'))\n",
    "else:\n",
    "    print(\"Error:\", response.json().get('error', 'Unknown error'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_reco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
